{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2224511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path to import from src\n",
    "import sys\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "if os.path.basename(cwd) == 'docs':\n",
    "    project_root = os.path.dirname(cwd)\n",
    "else:\n",
    "    project_root = cwd\n",
    "\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    print(f\"Added {src_path} to sys.path\")\n",
    "\n",
    "# Example usage of the new SCENICPLUS wrapper\n",
    "from methods import SCENICPLUS\n",
    "from datastruct import Dataset\n",
    "import numpy as np\n",
    "\n",
    "from analyze.Data import Data\n",
    "dataset = Data.from_json_url(\n",
    "    'https://bitbucket.org/sonnhammergrni/gs-datasets/raw/d2047430263f5ffe473525c74b4318f723c23b0e/N50/Tjarnberg-ID252384-D20151111-N50-E150-SNR100000-IDY252384.json'\n",
    ")\n",
    "# Run SCENIC+ (Standard)\n",
    "adj = SCENICPLUS( scenic_workflow_dir='src/methods/scenic_workflow/')\n",
    "\n",
    "# Run SCENIC+ with Nested Bootstrap\n",
    "# results = SCENICPLUS(\n",
    "#     dataset, \n",
    "#     cisTopic_obj_fname=\"/path/to/cistopic.pkl\",\n",
    "#     nested_boot=True,\n",
    "#     nest_runs=10,\n",
    "#     boot_runs=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d5a691",
   "metadata": {},
   "source": [
    "## modify and run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89697b9",
   "metadata": {},
   "source": [
    "#### Add this code to top of `scenicplus/src/scenicplus/snakemake/Snakefile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a60e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    " Get run_id from command line, default to '1' if not specified\n",
    "run_id = config.get('run_id', '1')\n",
    "\n",
    "# Update the output directory with the run_id\n",
    "config['params_general']['output_dir'] = config['params_general']['output_dir'].format(run_id=run_id)\n",
    "\n",
    "# Update all output paths with the output directory\n",
    "for key in config['output_data']:\n",
    "    config['output_data'][key] = config['output_data'][key].format(output_dir=config['params_general']['output_dir'])\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "shell(\"mkdir -p {config[params_general][output_dir]}\")\n",
    "\n",
    "configfile: \"config/config.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575fc12",
   "metadata": {},
   "source": [
    "#### Add rule for sampling data, add after previous code at top of snakemake file. Notice randomize commented part for Nested Bootstrapping null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule sample_data:\n",
    "    input:\n",
    "        GEX_anndata_fname=config[\"input_data\"][\"GEX_anndata_fname\"]\n",
    "    output:\n",
    "        GEX_anndata_sampled_fname=config[\"params_general\"][\"output_dir\"] + \"/GEX_anndata_sampled.h5ad\"\n",
    "    # params:\n",
    "        # random=config['params_general']['random']\n",
    "    run:\n",
    "        import scanpy as sc\n",
    "        import os\n",
    "        import numpy as np\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(output.GEX_anndata_sampled_fname), exist_ok=True)\n",
    "        \n",
    "        # Generate a random seed\n",
    "        random_seed = np.random.randint(0, 10000000)\n",
    "        \n",
    "        # Read the AnnData object\n",
    "        adata = sc.read_h5ad(input.GEX_anndata_fname)\n",
    "        \n",
    "        # randomize\n",
    "       numeric_columns = adata.obs.select_dtypes(include=['number']).columns.tolist()\n",
    "        \n",
    "        # Sample 10% of cells using the random seed\n",
    "        # if random==True:\n",
    "        # sc.pp.sample(adata, fraction=0.95, replace=False)\n",
    "        # for col in numeric_columns:\n",
    "        #    adata.obs[col] = np.random.permutation(adata.obs[col].values)\n",
    "        \n",
    "        # Save the sampled AnnData object\n",
    "        # adata.obs.index=adata.obs.index.str.split('-').str[0]+'-1'\n",
    "        adata.write(output.GEX_anndata_sampled_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc64af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {1..5}; do\n",
    "  snakemake --config run_id=$i -j 1 all\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3df902f",
   "metadata": {},
   "source": [
    "## postprocess data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the base directory to search for files\n",
    "base_directory = 'snakemake/results' ## or normal_results\n",
    "\n",
    "# List to hold DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the directory and its subdirectories\n",
    "for root, dirs, files in os.walk(base_directory):\n",
    "   for file in files:\n",
    "       if 'eRegulon' in file: # s_extended.tsv':  # Check for the specific file name\n",
    "           file_path = os.path.join(root, file)  # Get the full file path\n",
    "           df = pd.read_csv(file_path, sep='\\t')  # Load the DataFrame (assuming tab-separated values)\n",
    "           df['source_file'] = file_path  # Add a new column with the file path\n",
    "           dataframes.append(df)  # Append to the list\n",
    "\n",
    "# Optionally, concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df['init']=combined_df.source_file.str.split('/').str[2]\n",
    "combined_df=combined_df[['Gene','TF','importance_x_rho','init']]\n",
    "# Print the combined DataFrame\n",
    "combined_df.to_csv('cat_scenic.gz',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fe3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b2ca715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/apple/Developer/dcolinmorgan/pyNB/docs'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc747914",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\x0f'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m aa\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../src/methods/scenic_workflow/results/run_1.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/dcolinmorgan/pyNB/.venv/lib/python3.11/site-packages/pandas/io/pickle.py:208\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;66;03m# We want to silence any warnings about, e.g. moved modules.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[0;32m--> 208\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x0f'."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "try:\n",
    "    aa = joblib.load('../src/methods/scenic_workflow/results/run_1.pkl')\n",
    "    print(\"Successfully loaded with joblib\")\n",
    "except Exception as e:\n",
    "    print(f\"joblib load failed: {e}\")\n",
    "    # Fallback or debugging\n",
    "    import pickle\n",
    "    try:\n",
    "        with open('../src/methods/scenic_workflow/results/run_1.pkl', 'rb') as f:\n",
    "            aa = pickle.load(f)\n",
    "        print(\"Successfully loaded with pickle\")\n",
    "    except Exception as e2:\n",
    "        print(f\"pickle load failed: {e2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b015741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
