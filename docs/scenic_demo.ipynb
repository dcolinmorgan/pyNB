{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2224511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path to import from src\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Determine the project root\n",
    "# If running from docs/, root is one level up\n",
    "# If running from root/, root is current dir\n",
    "cwd = os.getcwd()\n",
    "if os.path.basename(cwd) == 'docs':\n",
    "    project_root = os.path.dirname(cwd)\n",
    "else:\n",
    "    project_root = cwd\n",
    "\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    print(f\"Added {src_path} to sys.path\")\n",
    "\n",
    "# Example usage of the new SCENICPLUS wrapper\n",
    "from methods import SCENICPLUS\n",
    "from datastruct import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Create a dummy dataset\n",
    "dataset = Dataset()\n",
    "dataset._Y = np.random.rand(100, 10) # 100 genes, 10 samples\n",
    "dataset._names = [f\"Gene_{i}\" for i in range(100)]\n",
    "\n",
    "# Run SCENIC+ (Standard)\n",
    "adj = SCENICPLUS(dataset, cisTopic_obj_fname=\"/path/to/cistopic.pkl\")\n",
    "\n",
    "# Run SCENIC+ with Nested Bootstrap\n",
    "# results = SCENICPLUS(\n",
    "#     dataset, \n",
    "#     cisTopic_obj_fname=\"/path/to/cistopic.pkl\",\n",
    "#     nested_boot=True,\n",
    "#     nest_runs=10,\n",
    "#     boot_runs=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d5a691",
   "metadata": {},
   "source": [
    "## modify and run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89697b9",
   "metadata": {},
   "source": [
    "#### Add this code to top of `scenicplus/src/scenicplus/snakemake/Snakefile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a60e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    " Get run_id from command line, default to '1' if not specified\n",
    "run_id = config.get('run_id', '1')\n",
    "\n",
    "# Update the output directory with the run_id\n",
    "config['params_general']['output_dir'] = config['params_general']['output_dir'].format(run_id=run_id)\n",
    "\n",
    "# Update all output paths with the output directory\n",
    "for key in config['output_data']:\n",
    "    config['output_data'][key] = config['output_data'][key].format(output_dir=config['params_general']['output_dir'])\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "shell(\"mkdir -p {config[params_general][output_dir]}\")\n",
    "\n",
    "configfile: \"config/config.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575fc12",
   "metadata": {},
   "source": [
    "#### Add rule for sampling data, add after previous code at top of snakemake file. Notice randomize commented part for Nested Bootstrapping null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule sample_data:\n",
    "    input:\n",
    "        GEX_anndata_fname=config[\"input_data\"][\"GEX_anndata_fname\"]\n",
    "    output:\n",
    "        GEX_anndata_sampled_fname=config[\"params_general\"][\"output_dir\"] + \"/GEX_anndata_sampled.h5ad\"\n",
    "    # params:\n",
    "        # random=config['params_general']['random']\n",
    "    run:\n",
    "        import scanpy as sc\n",
    "        import os\n",
    "        import numpy as np\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(output.GEX_anndata_sampled_fname), exist_ok=True)\n",
    "        \n",
    "        # Generate a random seed\n",
    "        random_seed = np.random.randint(0, 10000000)\n",
    "        \n",
    "        # Read the AnnData object\n",
    "        adata = sc.read_h5ad(input.GEX_anndata_fname)\n",
    "        \n",
    "        # randomize\n",
    "       numeric_columns = adata.obs.select_dtypes(include=['number']).columns.tolist()\n",
    "        \n",
    "        # Sample 10% of cells using the random seed\n",
    "        # if random==True:\n",
    "        # sc.pp.sample(adata, fraction=0.95, replace=False)\n",
    "        # for col in numeric_columns:\n",
    "        #    adata.obs[col] = np.random.permutation(adata.obs[col].values)\n",
    "        \n",
    "        # Save the sampled AnnData object\n",
    "        # adata.obs.index=adata.obs.index.str.split('-').str[0]+'-1'\n",
    "        adata.write(output.GEX_anndata_sampled_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc64af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {1..5}; do\n",
    "  snakemake --config run_id=$i -j 1 all\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3df902f",
   "metadata": {},
   "source": [
    "## postprocess data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the base directory to search for files\n",
    "base_directory = 'snakemake/results' ## or normal_results\n",
    "\n",
    "# List to hold DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the directory and its subdirectories\n",
    "for root, dirs, files in os.walk(base_directory):\n",
    "   for file in files:\n",
    "       if 'eRegulon' in file: # s_extended.tsv':  # Check for the specific file name\n",
    "           file_path = os.path.join(root, file)  # Get the full file path\n",
    "           df = pd.read_csv(file_path, sep='\\t')  # Load the DataFrame (assuming tab-separated values)\n",
    "           df['source_file'] = file_path  # Add a new column with the file path\n",
    "           dataframes.append(df)  # Append to the list\n",
    "\n",
    "# Optionally, concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df['init']=combined_df.source_file.str.split('/').str[2]\n",
    "combined_df=combined_df[['Gene','TF','importance_x_rho','init']]\n",
    "# Print the combined DataFrame\n",
    "combined_df.to_csv('cat_scenic.gz',compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
